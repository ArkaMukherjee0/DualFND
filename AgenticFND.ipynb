{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.environ.get('API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-agent Fake News Detection Framework\n",
    "\n",
    "- **Agent 1**: Take the input news piece and get a list of relevant facts\n",
    "- **Agent 2**: Reason with the input and the list of facts to decide whether news piece is fake\n",
    "\n",
    "![workflow](workflow.png \"Workflow of our simple 2-agent fake news detection framework\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent 1: FactBase\n",
    "\n",
    "1. We will use Gemini 1.5 Pro's better language understanding and enhanced knowledge base to get a decent base of facts.\n",
    "2. The facts will be returned as CSV, which will then be passed to Agent 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "def agent1_factbase(client, news_text):\n",
    "    \"\"\"\n",
    "    Agent 1: Extract relevant facts from the input news using Gemini 1.5 Pro\n",
    "    Returns facts in CSV format to be processed by Agent 2\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a fact-checking assistant. Given a news piece, extract a list of factual claims that can be verified.\n",
    "    For each claim, provide:\n",
    "    1. The claim\n",
    "    2. The source of the claim (if mentioned in the text)\n",
    "    3. A confidence score (0-1) on how verifiable this claim is based on specificity\n",
    "    \n",
    "    Format your output as CSV with headers: claim,source,confidence\n",
    "    Do not include any other text, explanations, or formatting - ONLY the CSV data.\n",
    "    \n",
    "    News piece to analyze:\n",
    "    {news_text}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-1.5-pro',\n",
    "        contents=prompt\n",
    "    )\n",
    "    \n",
    "    # Return the CSV string\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent 2: Verifier\n",
    "\n",
    "1. We will use the new Gemini 2.0 Flash model with zero-shot reasoning to get the final response: fake news or not.\n",
    "2. The final answer needs be returned in an XML format. This helps in easy integration with an existing code base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent2_verifier(client, news_text, facts_csv):\n",
    "    \"\"\"\n",
    "    Agent 2: Analyze the news and extracted facts to determine if the news is fake\n",
    "    Uses Gemini 2.0 Flash for faster reasoning\n",
    "    Returns analysis in XML format\n",
    "    \"\"\"\n",
    "    # Parse the CSV into a more readable format for the prompt\n",
    "    try:\n",
    "        facts_df = pd.read_csv(io.StringIO(facts_csv))\n",
    "        facts_formatted = \"\\n\".join([\n",
    "            f\"- Claim: {row['claim']}\\n  Source: {row['source']}\\n  Confidence: {row['confidence']}\"\n",
    "            for _, row in facts_df.iterrows()\n",
    "        ])\n",
    "    except:\n",
    "        # Fallback if CSV parsing fails\n",
    "        facts_formatted = facts_csv\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are a news verification assistant. Analyze the provided news piece and fact-check results to determine if the news is likely fake or genuine.\n",
    "    \n",
    "    News piece:\n",
    "    {news_text}\n",
    "    \n",
    "    Extracted facts and claims:\n",
    "    {facts_formatted}\n",
    "    \n",
    "    Analyze the news piece with the following considerations:\n",
    "    1. Do the extracted facts align with established knowledge?\n",
    "    2. Are there logical inconsistencies in the text?\n",
    "    3. Is the source reliable based on the extracted information?\n",
    "    4. Does the writing use manipulative or emotional language?\n",
    "    5. Are there any verifiable false claims?\n",
    "    \n",
    "    Provide your analysis in the following XML format, with no additional text before or after:\n",
    "    <verification>\n",
    "      <overall_assessment>1 for REAL or 0 for FAKE</overall_assessment>\n",
    "      <confidence_score>0-1 score</confidence_score>\n",
    "      <key_issues>List up to 3 key issues or red flags if any</key_issues>\n",
    "      <reasoning>Brief explanation of your reasoning</reasoning>\n",
    "    </verification>\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-2.0-flash',\n",
    "        contents=prompt\n",
    "    )\n",
    "    \n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_fake_news(client, news_text):\n",
    "    \"\"\"\n",
    "    Main function to orchestrate the 2-agent system for fake news detection\n",
    "    \"\"\"\n",
    "    # Step 1: Use Agent 1 to extract facts\n",
    "    facts_csv = agent1_factbase(client, news_text)\n",
    "    \n",
    "    # Step 2: Use Agent 2 to verify and reason about the news\n",
    "    verification_result = agent2_verifier(client, news_text, facts_csv)\n",
    "    \n",
    "    return {\n",
    "        \"facts_extracted\": facts_csv,\n",
    "        \"verification\": verification_result\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_detection_pipeline(client, news_text):\n",
    "    \"\"\"\n",
    "    Run the complete fake news detection pipeline and display the results\n",
    "    \"\"\"\n",
    "    print(\"üîç FAKE NEWS DETECTION ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Analyzing news:\\n{news_text[:300]}{'...' if len(news_text) > 300 else ''}\\n\")\n",
    "    \n",
    "    # Run the detection\n",
    "    results = detect_fake_news(client, news_text)\n",
    "    \n",
    "    # Display the results\n",
    "    print(\"üìä EXTRACTED FACTS (AGENT 1)\")\n",
    "    print(\"-\" * 50)\n",
    "    print(results[\"facts_extracted\"])\n",
    "    print(\"\\nüîé VERIFICATION RESULTS (AGENT 2)\")\n",
    "    print(\"-\" * 50)\n",
    "    print(results[\"verification\"])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking our FND framework for a spin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç FAKE NEWS DETECTION ANALYSIS\n",
      "==================================================\n",
      "Analyzing news:\n",
      "\n",
      "    Scientists at MIT have discovered a new type of battery that can be fully charged in 30 seconds and \n",
      "    lasts for a week of heavy use. The breakthrough, published yesterday in Nature, uses a revolutionary \n",
      "    graphene-based material that could make current lithium-ion batteries obsolete withi...\n",
      "\n",
      "üìä EXTRACTED FACTS (AGENT 1)\n",
      "--------------------------------------------------\n",
      "claim,source,confidence\n",
      "Scientists at MIT have discovered a new type of battery,,\"0.9\"\n",
      "The battery can be fully charged in 30 seconds,,\"0.9\"\n",
      "The battery lasts for a week of heavy use,,\"0.7\"\n",
      "The breakthrough was published yesterday in Nature,Nature,0.9\n",
      "The battery uses a graphene-based material,,\"0.9\"\n",
      "The new battery could make current lithium-ion batteries obsolete within two years,,\"0.5\"\n",
      "\n",
      "\n",
      "üîé VERIFICATION RESULTS (AGENT 2)\n",
      "--------------------------------------------------\n",
      "```xml\n",
      "<verification>\n",
      "  <overall_assessment>0</overall_assessment>\n",
      "  <confidence_score>0.8</confidence_score>\n",
      "  <key_issues>\n",
      "    <issue>Extraordinary claim about battery charging speed and longevity.</issue>\n",
      "    <issue>Overly optimistic prediction of lithium-ion battery obsolescence.</issue>\n",
      "    <issue>Lack of specific researcher or research group mentioned at MIT.</issue>\n",
      "  </key_issues>\n",
      "  <reasoning>While MIT is a reputable institution and Nature is a reputable journal, the claims about the battery's performance (30-second charging and a week of heavy use) are extremely ambitious and warrant significant skepticism. Such a breakthrough would likely be accompanied by more specific details about the researchers involved and the specific research group at MIT. The claim about lithium-ion batteries becoming obsolete in two years is also highly improbable given their widespread use and ongoing development. The combination of extraordinary claims with some missing details makes the news piece suspect. The mention of Nature as the source adds a layer of credibility, however, given the other red flags, it is more likely that the claim about Nature is false. A real announcement would likely include verifiable information like a DOI or at least a URL of the paper.</reasoning>\n",
      "</verification>\n",
      "```\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'facts_extracted': 'claim,source,confidence\\nScientists at MIT have discovered a new type of battery,,\"0.9\"\\nThe battery can be fully charged in 30 seconds,,\"0.9\"\\nThe battery lasts for a week of heavy use,,\"0.7\"\\nThe breakthrough was published yesterday in Nature,Nature,0.9\\nThe battery uses a graphene-based material,,\"0.9\"\\nThe new battery could make current lithium-ion batteries obsolete within two years,,\"0.5\"\\n',\n",
       " 'verification': \"```xml\\n<verification>\\n  <overall_assessment>0</overall_assessment>\\n  <confidence_score>0.8</confidence_score>\\n  <key_issues>\\n    <issue>Extraordinary claim about battery charging speed and longevity.</issue>\\n    <issue>Overly optimistic prediction of lithium-ion battery obsolescence.</issue>\\n    <issue>Lack of specific researcher or research group mentioned at MIT.</issue>\\n  </key_issues>\\n  <reasoning>While MIT is a reputable institution and Nature is a reputable journal, the claims about the battery's performance (30-second charging and a week of heavy use) are extremely ambitious and warrant significant skepticism. Such a breakthrough would likely be accompanied by more specific details about the researchers involved and the specific research group at MIT. The claim about lithium-ion batteries becoming obsolete in two years is also highly improbable given their widespread use and ongoing development. The combination of extraordinary claims with some missing details makes the news piece suspect. The mention of Nature as the source adds a layer of credibility, however, given the other red flags, it is more likely that the claim about Nature is false. A real announcement would likely include verifiable information like a DOI or at least a URL of the paper.</reasoning>\\n</verification>\\n```\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_news = \"\"\"\n",
    "    Scientists at MIT have discovered a new type of battery that can be fully charged in 30 seconds and \n",
    "    lasts for a week of heavy use. The breakthrough, published yesterday in Nature, uses a revolutionary \n",
    "    graphene-based material that could make current lithium-ion batteries obsolete within two years.\n",
    "    \"\"\"\n",
    "    \n",
    "run_detection_pipeline(client, sample_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting results for a small sample (500) from Uni-Fakeddit-55k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def agent1_factbase(client, news_text):\n",
    "    \"\"\"\n",
    "    Agent 1: Extract relevant facts from the input news using Gemini 1.5 Pro\n",
    "    Returns facts in CSV format to be processed by Agent 2\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a fact-checking assistant. Given a news piece, extract a list of factual claims that can be verified.\n",
    "    For each claim, provide:\n",
    "    1. The claim\n",
    "    2. The source of the claim (if mentioned in the text)\n",
    "    3. A confidence score (0-1) on how verifiable this claim is based on specificity\n",
    "    \n",
    "    Format your output as CSV with headers: claim,source,confidence\n",
    "    Do not include any other text, explanations, or formatting - ONLY the CSV data.\n",
    "    \n",
    "    News piece to analyze:\n",
    "    {news_text}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model='gemini-1.5-pro',\n",
    "            contents=prompt\n",
    "        )\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Agent 1: {e}\")\n",
    "        # Return a simple CSV with error information\n",
    "        return \"claim,source,confidence\\nError processing input,agent1,0.0\"\n",
    "\n",
    "def agent2_verifier(client, news_text, facts_csv):\n",
    "    \"\"\"\n",
    "    Agent 2: Analyze the news and extracted facts to determine if the news is fake\n",
    "    Uses Gemini 2.0 Flash for faster reasoning\n",
    "    Returns analysis in XML format with binary classification (1=REAL, 0=FAKE)\n",
    "    \"\"\"\n",
    "    # Parse the CSV into a more readable format for the prompt\n",
    "    try:\n",
    "        facts_df = pd.read_csv(io.StringIO(facts_csv))\n",
    "        facts_formatted = \"\\n\".join([\n",
    "            f\"- Claim: {row['claim']}\\n  Source: {row['source']}\\n  Confidence: {row['confidence']}\"\n",
    "            for _, row in facts_df.iterrows()\n",
    "        ])\n",
    "    except:\n",
    "        # Fallback if CSV parsing fails\n",
    "        facts_formatted = facts_csv\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are a news verification assistant. Analyze the provided news piece and fact-check results to determine if the news is likely fake or genuine.\n",
    "    \n",
    "    News piece:\n",
    "    {news_text}\n",
    "    \n",
    "    Extracted facts and claims:\n",
    "    {facts_formatted}\n",
    "    \n",
    "    Analyze the news piece with the following considerations:\n",
    "    1. Do the extracted facts align with established knowledge?\n",
    "    2. Are there logical inconsistencies in the text?\n",
    "    3. Is the source reliable based on the extracted information?\n",
    "    4. Does the writing use manipulative or emotional language?\n",
    "    5. Are there any verifiable false claims?\n",
    "    \n",
    "    Provide your analysis in the following XML format, with no additional text before or after:\n",
    "    <verification>\n",
    "      <overall_assessment>1 for REAL or 0 for FAKE</overall_assessment>\n",
    "      <confidence_score>0-1 score</confidence_score>\n",
    "      <key_issues>List up to 3 key issues or red flags if any</key_issues>\n",
    "      <reasoning>Brief explanation of your reasoning</reasoning>\n",
    "    </verification>\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model='gemini-2.0-flash',\n",
    "            contents=prompt\n",
    "        )\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Agent 2: {e}\")\n",
    "        # Return a simple XML with error information\n",
    "        return \"<verification>\\n  <overall_assessment>0</overall_assessment>\\n  <confidence_score>0.0</confidence_score>\\n  <key_issues>Error processing input</key_issues>\\n  <reasoning>Agent 2 encountered an error</reasoning>\\n</verification>\"\n",
    "\n",
    "def detect_fake_news(client, news_text):\n",
    "    \"\"\"\n",
    "    Main function to orchestrate the 2-agent system for fake news detection\n",
    "    \"\"\"\n",
    "    # Step 1: Use Agent 1 to extract facts\n",
    "    facts_csv = agent1_factbase(client, news_text)\n",
    "    \n",
    "    # Step 2: Use Agent 2 to verify and reason about the news\n",
    "    verification_result = agent2_verifier(client, news_text, facts_csv)\n",
    "    \n",
    "    return {\n",
    "        \"facts_extracted\": facts_csv,\n",
    "        \"verification\": verification_result\n",
    "    }\n",
    "\n",
    "def parse_dataset_line(line):\n",
    "    \"\"\"\n",
    "    Parse a line from the Uni-Fakkedit-55k dataset\n",
    "    Returns a tuple of (text, objects, label) or None if parsing fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract text\n",
    "        text_parts = line.split(\"[TEXT]\")\n",
    "        if len(text_parts) != 2:\n",
    "            return None\n",
    "        after_text = text_parts[1]\n",
    "\n",
    "        # Extract objects\n",
    "        text_objects_parts = after_text.split(\"[OBJECTS]\")\n",
    "        if len(text_objects_parts) != 2:\n",
    "            return None\n",
    "        text_part = text_objects_parts[0].strip()\n",
    "        after_objects = text_objects_parts[1]\n",
    "\n",
    "        # Extract label\n",
    "        objects_label_parts = after_objects.split(\"[LABEL]\")\n",
    "        if len(objects_label_parts) != 2:\n",
    "            return None\n",
    "        objects_part = objects_label_parts[0].strip()\n",
    "        label_part = objects_label_parts[1].strip()\n",
    "\n",
    "        # Combine text and objects\n",
    "        combined_input = f\"{text_part}. The image contains: {objects_part}\"\n",
    "        label_int = int(label_part)\n",
    "        \n",
    "        return (combined_input, label_int)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing line: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_assessment(verification_xml):\n",
    "    \"\"\"\n",
    "    Extract the overall assessment (1 or 0) from the verification XML\n",
    "    Returns the assessment value or None if extraction fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if \"<overall_assessment>1</overall_assessment>\" in verification_xml:\n",
    "            return 1\n",
    "        elif \"<overall_assessment>0</overall_assessment>\" in verification_xml:\n",
    "            return 0\n",
    "        else:\n",
    "            # Try to extract using a more flexible approach\n",
    "            start_tag = \"<overall_assessment>\"\n",
    "            end_tag = \"</overall_assessment>\"\n",
    "            start_pos = verification_xml.find(start_tag)\n",
    "            if start_pos == -1:\n",
    "                return None\n",
    "            start_pos += len(start_tag)\n",
    "            end_pos = verification_xml.find(end_tag, start_pos)\n",
    "            if end_pos == -1:\n",
    "                return None\n",
    "            assessment_str = verification_xml[start_pos:end_pos].strip()\n",
    "            if assessment_str == \"1\" or assessment_str.upper() == \"REAL\":\n",
    "                return 1\n",
    "            elif assessment_str == \"0\" or assessment_str.upper() == \"FAKE\":\n",
    "                return 0\n",
    "            else:\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting assessment: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_dataset(client, dataset_path, output_path, num_samples=500, batch_size=10):\n",
    "    \"\"\"\n",
    "    Process the first num_samples entries from the Uni-Fakkedit-55k dataset\n",
    "    Saves results to a CSV file and returns evaluation metrics\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    correct_predictions = 0\n",
    "    total_processed = 0\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    # Open output file for writing results as we go\n",
    "    with open(output_path, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['text', 'true_label', 'predicted_label', 'correct', 'facts', 'verification']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # Process the dataset\n",
    "        with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "            lines = []\n",
    "            for _ in range(num_samples):\n",
    "                line = f.readline()\n",
    "                if not line:\n",
    "                    break  # End of file\n",
    "                lines.append(line)\n",
    "            \n",
    "            # Process in batches to avoid rate limiting\n",
    "            for i in tqdm(range(0, len(lines), batch_size), desc=\"Processing dataset\"):\n",
    "                batch_lines = lines[i:i+batch_size]\n",
    "                batch_results = []\n",
    "                \n",
    "                for line in batch_lines:\n",
    "                    parsed_data = parse_dataset_line(line)\n",
    "                    if parsed_data is None:\n",
    "                        continue\n",
    "                    \n",
    "                    combined_input, true_label = parsed_data\n",
    "                    \n",
    "                    # Run fake news detection\n",
    "                    detection_result = detect_fake_news(client, combined_input)\n",
    "                    \n",
    "                    # Extract prediction\n",
    "                    predicted_label = extract_assessment(detection_result[\"verification\"])\n",
    "                    \n",
    "                    # Calculate if prediction is correct\n",
    "                    correct = (predicted_label == true_label) if predicted_label is not None else False\n",
    "                    if correct:\n",
    "                        correct_predictions += 1\n",
    "                    \n",
    "                    # Store result\n",
    "                    result = {\n",
    "                        'text': combined_input,\n",
    "                        'true_label': true_label,\n",
    "                        'predicted_label': predicted_label,\n",
    "                        'correct': correct,\n",
    "                        'facts': detection_result[\"facts_extracted\"],\n",
    "                        'verification': detection_result[\"verification\"]\n",
    "                    }\n",
    "                    batch_results.append(result)\n",
    "                    total_processed += 1\n",
    "                \n",
    "                # Write batch results to CSV\n",
    "                for result in batch_results:\n",
    "                    writer.writerow(result)\n",
    "                    results.append(result)\n",
    "                \n",
    "                # Sleep to avoid rate limiting\n",
    "                if i + batch_size < len(lines):\n",
    "                    time.sleep(2)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / total_processed if total_processed > 0 else 0\n",
    "    \n",
    "    print(f\"\\nProcessed {total_processed} samples\")\n",
    "    print(f\"Correct predictions: {correct_predictions}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'results': results,\n",
    "        'accuracy': accuracy,\n",
    "        'correct_predictions': correct_predictions,\n",
    "        'total_processed': total_processed\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing of 500 samples from C:\\Users\\CoolA\\Code\\dataset_2way_output.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [21:45<35:30, 68.72s/it]\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\u011f' in position 147: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting processing of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 8\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     11\u001b[0m processing_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[1;32mIn[10], line 237\u001b[0m, in \u001b[0;36mprocess_dataset\u001b[1;34m(client, dataset_path, output_path, num_samples, batch_size)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;66;03m# Write batch results to CSV\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m batch_results:\n\u001b[1;32m--> 237\u001b[0m     \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriterow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# Sleep to avoid rate limiting\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\csv.py:154\u001b[0m, in \u001b[0;36mDictWriter.writerow\u001b[1;34m(self, rowdict)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwriterow\u001b[39m(\u001b[38;5;28mself\u001b[39m, rowdict):\n\u001b[1;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39mwriterow(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dict_to_list(rowdict))\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\cp1252.py:19\u001b[0m, in \u001b[0;36mIncrementalEncoder.encode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mcharmap_encode(\u001b[38;5;28minput\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,encoding_table)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\u011f' in position 147: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "dataset_path = r'C:\\Users\\CoolA\\Code\\dataset_2way_output.txt'\n",
    "output_path=\"results/fakkedit_results.csv\"\n",
    "num_samples=500\n",
    "\n",
    "print(f\"Starting processing of {num_samples} samples from {dataset_path}\")\n",
    "start_time = time.time()\n",
    "\n",
    "metrics = process_dataset(client, dataset_path, output_path, num_samples)\n",
    "\n",
    "end_time = time.time()\n",
    "processing_time = end_time - start_time\n",
    "\n",
    "print(f\"\\nProcessing completed in {processing_time:.2f} seconds\")\n",
    "print(f\"Results saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ultra-fast Agentic FND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing of 500 samples from C:\\Users\\CoolA\\Code\\dataset_2way_output.txt\n",
      "Output will be saved to results/fakkedit_results.csv\n",
      "Running performance test...\n",
      "Test processing time: 8.64s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  11%|‚ñà         | 11/100 [03:11<30:42, 20.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Agent 1 took 11.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [27:34<00:00, 16.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 500 samples\n",
      "Correct predictions: 334\n",
      "Accuracy: 0.6680\n",
      "Average processing time per entry: 6.57s\n",
      "Min processing time: 3.13s\n",
      "Max processing time: 14.64s\n",
      "\n",
      "Processing completed in 1654.12 seconds\n",
      "Average speed: 0.30 entries per second\n",
      "Results saved to results/fakkedit_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import os\n",
    "import concurrent.futures\n",
    "import re\n",
    "from functools import lru_cache\n",
    "import threading\n",
    "\n",
    "def agent1_factbase(client, news_text):\n",
    "    \"\"\"\n",
    "    Agent 1: Extract relevant facts from the input news using Gemini 1.5 Pro\n",
    "    Returns facts in CSV format to be processed by Agent 2\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a simpler prompt for faster processing\n",
    "    prompt = f\"\"\"\n",
    "    Extract verifiable claims from this text as CSV with headers \"claim,source,confidence\":\n",
    "    {news_text}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model='gemini-1.5-pro',\n",
    "            contents=prompt\n",
    "        )\n",
    "        result = response.text\n",
    "        \n",
    "        # Ensure it's valid CSV format\n",
    "        if not \"claim,source,confidence\" in result:\n",
    "            result = \"claim,source,confidence\\n\" + result.replace('\\n', ' ').strip()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in Agent 1: {e}\")\n",
    "        result = \"claim,source,confidence\\nError processing input,agent1,0.0\"\n",
    "        \n",
    "    end_time = time.time()\n",
    "    processing_time = end_time - start_time\n",
    "    \n",
    "    # Print timing only if it's exceptionally slow\n",
    "    if processing_time > 10:\n",
    "        print(f\"‚ö†Ô∏è Agent 1 took {processing_time:.2f}s\")\n",
    "        \n",
    "    return result\n",
    "\n",
    "# Use a regex pattern to extract assessment value\n",
    "ASSESSMENT_PATTERN = re.compile(r'<overall_assessment>([01]|REAL|FAKE)</overall_assessment>')\n",
    "\n",
    "def agent2_verifier(client, news_text, facts_csv):\n",
    "    \"\"\"\n",
    "    Agent 2: Analyze the news and extracted facts to determine if the news is fake\n",
    "    Uses Gemini 2.0 Flash for faster reasoning\n",
    "    Returns analysis in XML format with binary classification (1=REAL, 0=FAKE)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a more compact facts representation\n",
    "    try:\n",
    "        facts_df = pd.read_csv(io.StringIO(facts_csv))\n",
    "        # Limit to top 3 facts for efficiency\n",
    "        facts_df = facts_df.head(3)\n",
    "        facts_formatted = \"; \".join([\n",
    "            f\"Claim: {row['claim']} (Source: {row['source']}, Conf: {row['confidence']})\"\n",
    "            for _, row in facts_df.iterrows()\n",
    "        ])\n",
    "    except:\n",
    "        facts_formatted = facts_csv\n",
    "    \n",
    "    # Create a simpler prompt for faster processing\n",
    "    prompt = f\"\"\"\n",
    "    Classify if this news is real (1) or fake (0) based on these facts. Return in XML:\n",
    "    <verification>\n",
    "      <overall_assessment>1 for REAL or 0 for FAKE</overall_assessment>\n",
    "      <confidence_score>0-1</confidence_score>\n",
    "      <key_issues>Brief issues</key_issues>\n",
    "      <reasoning>Brief reasoning</reasoning>\n",
    "    </verification>\n",
    "    \n",
    "    News: {news_text}\n",
    "    Facts: {facts_formatted}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model='gemini-2.0-flash',\n",
    "            contents=prompt\n",
    "        )\n",
    "        result = response.text\n",
    "        \n",
    "        # Ensure it has the required XML format\n",
    "        if not \"<verification>\" in result:\n",
    "            result = f\"\"\"<verification>\n",
    "  <overall_assessment>0</overall_assessment>\n",
    "  <confidence_score>0.5</confidence_score>\n",
    "  <key_issues>Malformed response</key_issues>\n",
    "  <reasoning>Could not properly analyze the content</reasoning>\n",
    "</verification>\"\"\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in Agent 2: {e}\")\n",
    "        result = \"\"\"<verification>\n",
    "  <overall_assessment>0</overall_assessment>\n",
    "  <confidence_score>0.0</confidence_score>\n",
    "  <key_issues>Error processing input</key_issues>\n",
    "  <reasoning>Agent 2 encountered an error</reasoning>\n",
    "</verification>\"\"\"\n",
    "        \n",
    "    end_time = time.time()\n",
    "    processing_time = end_time - start_time\n",
    "    \n",
    "    # Print timing only if it's exceptionally slow\n",
    "    if processing_time > 10:\n",
    "        print(f\"‚ö†Ô∏è Agent 2 took {processing_time:.2f}s\")\n",
    "        \n",
    "    return result\n",
    "\n",
    "@lru_cache(maxsize=1024)\n",
    "def detect_fake_news(client, news_text):\n",
    "    \"\"\"\n",
    "    Main function to orchestrate the 2-agent system for fake news detection\n",
    "    Added caching to avoid reprocessing identical entries\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Step 1: Use Agent 1 to extract facts\n",
    "    facts_csv = agent1_factbase(client, news_text)\n",
    "    \n",
    "    # Step 2: Use Agent 2 to verify and reason about the news\n",
    "    verification_result = agent2_verifier(client, news_text, facts_csv)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    # Print total time if it's exceptionally slow\n",
    "    if total_time > 30:\n",
    "        print(f\"‚ö†Ô∏è Total processing took {total_time:.2f}s for: {news_text[:50]}...\")\n",
    "        \n",
    "    return {\n",
    "        \"facts_extracted\": facts_csv,\n",
    "        \"verification\": verification_result,\n",
    "        \"processing_time\": total_time\n",
    "    }\n",
    "\n",
    "def parse_dataset_line(line):\n",
    "    \"\"\"\n",
    "    Parse a line from the Uni-Fakkedit-55k dataset\n",
    "    Returns a tuple of (text, objects, label) or None if parsing fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract text\n",
    "        text_parts = line.split(\"[TEXT]\")\n",
    "        if len(text_parts) != 2:\n",
    "            return None\n",
    "        after_text = text_parts[1]\n",
    "\n",
    "        # Extract objects\n",
    "        text_objects_parts = after_text.split(\"[OBJECTS]\")\n",
    "        if len(text_objects_parts) != 2:\n",
    "            return None\n",
    "        text_part = text_objects_parts[0].strip()\n",
    "        after_objects = text_objects_parts[1]\n",
    "\n",
    "        # Extract label\n",
    "        objects_label_parts = after_objects.split(\"[LABEL]\")\n",
    "        if len(objects_label_parts) != 2:\n",
    "            return None\n",
    "        objects_part = objects_label_parts[0].strip()\n",
    "        label_part = objects_label_parts[1].strip()\n",
    "\n",
    "        # Combine text and objects - keep it short\n",
    "        combined_input = f\"{text_part}. Objects: {objects_part}\"\n",
    "        label_int = int(label_part)\n",
    "        \n",
    "        return (combined_input, label_int)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing line: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_assessment(verification_xml):\n",
    "    \"\"\"\n",
    "    Extract the overall assessment (1 or 0) from the verification XML\n",
    "    Returns the assessment value or None if extraction fails\n",
    "    Uses regex for faster extraction\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use regex pattern for faster extraction\n",
    "        match = ASSESSMENT_PATTERN.search(verification_xml)\n",
    "        if match:\n",
    "            assessment_str = match.group(1)\n",
    "            if assessment_str == \"1\" or assessment_str.upper() == \"REAL\":\n",
    "                return 1\n",
    "            elif assessment_str == \"0\" or assessment_str.upper() == \"FAKE\":\n",
    "                return 0\n",
    "        \n",
    "        # Fallback to simple string check\n",
    "        if \"<overall_assessment>1</overall_assessment>\" in verification_xml:\n",
    "            return 1\n",
    "        elif \"<overall_assessment>0</overall_assessment>\" in verification_xml:\n",
    "            return 0\n",
    "        \n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting assessment: {e}\")\n",
    "        return None\n",
    "\n",
    "def sanitize_for_csv(text):\n",
    "    \"\"\"\n",
    "    Sanitize text to ensure it can be written to CSV safely\n",
    "    Handles Unicode characters and other potential encoding issues\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    \n",
    "    # Replace problematic characters that might cause issues\n",
    "    return str(text).replace('\\r', ' ').replace('\\n', ' ')\n",
    "\n",
    "def process_batch(client, batch_lines, lock, output_path, writer=None):\n",
    "    \"\"\"\n",
    "    Process a batch of dataset lines\n",
    "    Returns a list of results for the batch\n",
    "    \"\"\"\n",
    "    batch_results = []\n",
    "    batch_timings = []\n",
    "    \n",
    "    for line in batch_lines:\n",
    "        parsed_data = parse_dataset_line(line)\n",
    "        if parsed_data is None:\n",
    "            continue\n",
    "        \n",
    "        combined_input, true_label = parsed_data\n",
    "        \n",
    "        # Process start time\n",
    "        entry_start_time = time.time()\n",
    "        \n",
    "        # Run fake news detection\n",
    "        detection_result = detect_fake_news(client, combined_input)\n",
    "        \n",
    "        # Extract prediction\n",
    "        predicted_label = extract_assessment(detection_result[\"verification\"])\n",
    "        \n",
    "        # Calculate if prediction is correct\n",
    "        correct = (predicted_label == true_label) if predicted_label is not None else False\n",
    "        \n",
    "        # Record processing time\n",
    "        entry_time = time.time() - entry_start_time\n",
    "        batch_timings.append(entry_time)\n",
    "        \n",
    "        # Sanitize data for CSV output\n",
    "        safe_text = sanitize_for_csv(combined_input)\n",
    "        safe_facts = sanitize_for_csv(detection_result[\"facts_extracted\"])\n",
    "        safe_verification = sanitize_for_csv(detection_result[\"verification\"])\n",
    "        \n",
    "        # Store result\n",
    "        result = {\n",
    "            'text': safe_text,\n",
    "            'true_label': true_label,\n",
    "            'predicted_label': predicted_label,\n",
    "            'correct': correct,\n",
    "            'facts': safe_facts,\n",
    "            'verification': safe_verification,\n",
    "            'processing_time': entry_time\n",
    "        }\n",
    "        batch_results.append(result)\n",
    "        \n",
    "        # Write result to CSV if provided with a writer\n",
    "        if writer:\n",
    "            with lock:\n",
    "                try:\n",
    "                    writer.writerow(result)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error writing to CSV: {e}\")\n",
    "                    # Try writing a simplified version\n",
    "                    simple_result = {\n",
    "                        'text': 'Unicode error - text removed',\n",
    "                        'true_label': true_label,\n",
    "                        'predicted_label': predicted_label,\n",
    "                        'correct': correct,\n",
    "                        'facts': 'Unicode error - text removed',\n",
    "                        'verification': 'Unicode error - text removed',\n",
    "                        'processing_time': entry_time\n",
    "                    }\n",
    "                    writer.writerow(simple_result)\n",
    "    \n",
    "    return batch_results, batch_timings\n",
    "\n",
    "def process_dataset(client, dataset_path, output_path, num_samples=500, batch_size=5, max_workers=2):\n",
    "    \"\"\"\n",
    "    Process the first num_samples entries from the Uni-Fakkedit-55k dataset\n",
    "    Saves results to a CSV file and returns evaluation metrics\n",
    "    Uses parallel processing for faster execution\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    processing_times = []\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    # Read the dataset lines\n",
    "    with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "        lines = []\n",
    "        for _ in range(num_samples):\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break  # End of file\n",
    "            lines.append(line)\n",
    "    \n",
    "    # Create CSV file and writer with UTF-8 encoding\n",
    "    csvfile = open(output_path, 'w', newline='', encoding='utf-8')\n",
    "    fieldnames = ['text', 'true_label', 'predicted_label', 'correct', 'facts', 'verification', 'processing_time']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # Create a thread lock for CSV writing\n",
    "    lock = threading.Lock()\n",
    "    \n",
    "    # Process batches with ThreadPoolExecutor for parallel processing\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit batch processing tasks\n",
    "        futures = []\n",
    "        for i in range(0, len(lines), batch_size):\n",
    "            batch_lines = lines[i:i+batch_size]\n",
    "            futures.append(executor.submit(process_batch, client, batch_lines, lock, output_path, writer))\n",
    "        \n",
    "        # Process results as they complete\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Processing batches\"):\n",
    "            batch_results, batch_timings = future.result()\n",
    "            results.extend(batch_results)\n",
    "            processing_times.extend(batch_timings)\n",
    "    \n",
    "    # Close CSV file\n",
    "    csvfile.close()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    correct_predictions = sum(1 for result in results if result['correct'])\n",
    "    total_processed = len(results)\n",
    "    accuracy = correct_predictions / total_processed if total_processed > 0 else 0\n",
    "    avg_processing_time = sum(processing_times) / len(processing_times) if processing_times else 0\n",
    "    max_processing_time = max(processing_times) if processing_times else 0\n",
    "    min_processing_time = min(processing_times) if processing_times else 0\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nProcessed {total_processed} samples\")\n",
    "    print(f\"Correct predictions: {correct_predictions}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Average processing time per entry: {avg_processing_time:.2f}s\")\n",
    "    print(f\"Min processing time: {min_processing_time:.2f}s\")\n",
    "    print(f\"Max processing time: {max_processing_time:.2f}s\")\n",
    "    \n",
    "    return {\n",
    "        'results': results,\n",
    "        'accuracy': accuracy,\n",
    "        'correct_predictions': correct_predictions,\n",
    "        'total_processed': total_processed,\n",
    "        'avg_processing_time': avg_processing_time,\n",
    "        'min_processing_time': min_processing_time,\n",
    "        'max_processing_time': max_processing_time\n",
    "    }\n",
    "\n",
    "dataset_path = r\"C:\\Users\\CoolA\\Code\\dataset_2way_output.txt\"\n",
    "\n",
    "print(f\"Starting processing of {num_samples} samples from {dataset_path}\")\n",
    "print(f\"Output will be saved to {output_path}\")\n",
    "\n",
    "# Make sure the output directory exists\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "# Run a quick test to measure base performance\n",
    "print(\"Running performance test...\")\n",
    "test_news = \"Scientists discovered a new type of battery that can be charged in seconds.\"\n",
    "start_time = time.time()\n",
    "test_result = detect_fake_news(client, test_news)\n",
    "test_time = time.time() - start_time\n",
    "print(f\"Test processing time: {test_time:.2f}s\")\n",
    "\n",
    "# Start main processing\n",
    "start_time = time.time()\n",
    "metrics = process_dataset(client, dataset_path, output_path, num_samples)\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "entries_per_second = metrics['total_processed'] / total_time if total_time > 0 else 0\n",
    "\n",
    "print(f\"\\nProcessing completed in {total_time:.2f} seconds\")\n",
    "print(f\"Average speed: {entries_per_second:.2f} entries per second\")\n",
    "print(f\"Results saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Findings\n",
    "\n",
    "1. 5-piece FND: **72.86%** accuracy, 6.55 eps\n",
    "2. 3-piece FND: **66.80%** accuracy, 0.30 eps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
